{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6190cf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.057452,
     "end_time": "2025-12-10T18:57:50.139668",
     "exception": false,
     "start_time": "2025-12-10T18:57:48.082216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21450f2d",
   "metadata": {
    "papermill": {
     "duration": 0.056191,
     "end_time": "2025-12-10T18:57:50.200546",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.144355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EDA analysis on titanic training dataset\n",
    "df= pd.read_csv(\"data\\\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e431e3d",
   "metadata": {
    "papermill": {
     "duration": 0.033359,
     "end_time": "2025-12-10T18:57:50.238943",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.205584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create basic EDA \n",
    "df.info()    # basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9b571",
   "metadata": {
    "papermill": {
     "duration": 0.038596,
     "end_time": "2025-12-10T18:57:50.282259",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.243663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()  # statistics summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb38da",
   "metadata": {
    "papermill": {
     "duration": 0.016087,
     "end_time": "2025-12-10T18:57:50.303305",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.287218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isnull().sum() # check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28328f40",
   "metadata": {
    "papermill": {
     "duration": 0.017714,
     "end_time": "2025-12-10T18:57:50.326016",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.308302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad33fe9",
   "metadata": {
    "papermill": {
     "duration": 0.017256,
     "end_time": "2025-12-10T18:57:50.348618",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.331362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Survived'].value_counts(normalize=True)*100  \n",
    "#about 38% survived, so dataset is imbalanced, the 'class 0' has more weight that 'class 1'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a7e10",
   "metadata": {
    "papermill": {
     "duration": 0.32292,
     "end_time": "2025-12-10T18:57:50.676793",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.353873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Handling missing values, Filling missing Age with median, Embarked with mode\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "# Age distribution\n",
    "plt.hist(df['Age'].dropna(), bins=30)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b40911",
   "metadata": {
    "papermill": {
     "duration": 0.217086,
     "end_time": "2025-12-10T18:57:50.899483",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.682397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fare Distribution\n",
    "\n",
    "plt.hist(df['Fare'].dropna(), bins=30)\n",
    "plt.title('Fare distribution')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3883e",
   "metadata": {
    "papermill": {
     "duration": 0.020199,
     "end_time": "2025-12-10T18:57:50.925844",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.905645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby('Sex')['Survived'].mean()*100\n",
    "# 74% of all woman survived , while ~19% of all men survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611349a1",
   "metadata": {
    "papermill": {
     "duration": 0.017858,
     "end_time": "2025-12-10T18:57:50.949856",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.931998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Sex'].value_counts(normalize=True)*100\n",
    "# total travelers were about 65% were men , and ~ 35% woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ae184",
   "metadata": {
    "papermill": {
     "duration": 0.017747,
     "end_time": "2025-12-10T18:57:50.973749",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.956002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby('Pclass')['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9378f59",
   "metadata": {
    "papermill": {
     "duration": 0.021741,
     "end_time": "2025-12-10T18:57:51.001939",
     "exception": false,
     "start_time": "2025-12-10T18:57:50.980198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # survival % for kids <= 12 years\n",
    "cond = df['Age'].le(12, fill_value=False)\n",
    "df.groupby(cond)['Survived'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f1ec8",
   "metadata": {
    "papermill": {
     "duration": 1.62434,
     "end_time": "2025-12-10T18:57:52.633455",
     "exception": false,
     "start_time": "2025-12-10T18:57:51.009115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SVM Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Select features and target\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "\n",
    "#Encoding categorical variables\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "# defning X and y\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#Scale features \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Train SVM model\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate SVM model\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512cc398",
   "metadata": {
    "papermill": {
     "duration": 0.00709,
     "end_time": "2025-12-10T18:57:52.646951",
     "exception": false,
     "start_time": "2025-12-10T18:57:52.639861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The SVM model predicts survival about 81.6% of the time.\n",
    "The SVM model correctly predicted that 93 people die (0)\n",
    "The SVM model correctly predicted that 53 People survived (1)\n",
    "The SVM model mistaked that 12 survived but they didn't\n",
    "The SVM model mistaked that 21  died but they survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcec293",
   "metadata": {
    "papermill": {
     "duration": 0.059457,
     "end_time": "2025-12-10T18:57:52.712814",
     "exception": false,
     "start_time": "2025-12-10T18:57:52.653357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(max_iter=500)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "y_pred_log = log_model.predict(X_test_scaled)\n",
    "print(\"===== Logistic Regression Results =====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe5846",
   "metadata": {
    "papermill": {
     "duration": 0.209953,
     "end_time": "2025-12-10T18:57:52.932739",
     "exception": false,
     "start_time": "2025-12-10T18:57:52.722786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train, y_train)  # Decision trees not require scaling\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"===== Decision Tree Results =====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d094c2",
   "metadata": {
    "papermill": {
     "duration": 2.96993,
     "end_time": "2025-12-10T18:57:55.909134",
     "exception": false,
     "start_time": "2025-12-10T18:57:52.939204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Neural Network (MLPClassifier)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # two layers: 64 â†’ 32 nodes\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Neural Network\n",
    "y_pred_nn = nn_model.predict(X_test_scaled)\n",
    "print(\"===== Neural Network (MLP) Results =====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nn))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nn))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199fffc",
   "metadata": {
    "papermill": {
     "duration": 17.351715,
     "end_time": "2025-12-10T18:58:13.269145",
     "exception": false,
     "start_time": "2025-12-10T18:57:55.917430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating the algorithms with Cross Validation to estimate\n",
    "# how well the model will generalize to unseen data\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)  # Cross-validation setup\n",
    "\n",
    "# Compute cross-validation scores\n",
    "cv_results = {\n",
    "    \"SVM\": cross_val_score(svm_model, X_scaled, y, cv=kfold, scoring='accuracy'),\n",
    "    \"Logistic Regression\": cross_val_score(log_model, X_scaled, y, cv=kfold, scoring='accuracy'),\n",
    "    \"Decision Tree\": cross_val_score(dt_model, X, y, cv=kfold, scoring='accuracy'),  # no scaling\n",
    "    \"Neural Network\": cross_val_score(nn_model, X_scaled, y, cv=kfold, scoring='accuracy')\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\n======= Cross-Validation Results (5-Fold) =======\")\n",
    "for model, scores in cv_results.items():\n",
    "    print(f\"\\n{model}\")\n",
    "    print(f\"Scores: {scores}\")\n",
    "    print(f\"Mean Accuracy: {scores.mean():.4f}\")\n",
    "    print(f\"Standard Deviation: {scores.std():.4f}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n======= Full Train/Test Evaluation =======\")\n",
    "\n",
    "# SVM\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"\\n--- SVM ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_model.predict(X_test_scaled)))\n",
    "\n",
    "# Logistic Regression\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "print(\"\\n--- Logistic Regression ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, log_model.predict(X_test_scaled)))\n",
    "\n",
    "# Decision Tree\n",
    "dt_model.fit(X_train, y_train)\n",
    "print(\"\\n--- Decision Tree ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_model.predict(X_test)))\n",
    "\n",
    "# Neural Network\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "print(\"\\n--- Neural Network (MLP) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nn_model.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5aa76",
   "metadata": {
    "papermill": {
     "duration": 8.63456,
     "end_time": "2025-12-10T18:58:21.910737",
     "exception": false,
     "start_time": "2025-12-10T18:58:13.276177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SVM Hyperparameter Optimization (GridSearchCV)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# FEATURES & TARGET\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = df[features]\n",
    "y = df['Survived']\n",
    "\n",
    "# COLUMNS BY TYPE\n",
    "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "# PREPROCESSING PIPELINES\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# SVM MODEL (PIPELINE)\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", SVC())\n",
    "])\n",
    "\n",
    "# HYPERPARAMETER GRID\n",
    "param_grid = {\n",
    "    \"model__C\": [0.1, 1, 10, 50, 100],\n",
    "    \"model__gamma\": [\"scale\", \"auto\", 0.1, 0.01, 0.001],\n",
    "    \"model__kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
    "}\n",
    "\n",
    "# GRID SEARCH (5-FOLD)\n",
    "grid = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# TRAIN/TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# RESULTS\n",
    "print(\"\\n===== Best Hyperparameters Found =====\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Extract all 5-fold scores for the best model\n",
    "cv_scores = grid.cv_results_['split0_test_score'][grid.best_index_], \\\n",
    "            grid.cv_results_['split1_test_score'][grid.best_index_], \\\n",
    "            grid.cv_results_['split2_test_score'][grid.best_index_], \\\n",
    "            grid.cv_results_['split3_test_score'][grid.best_index_], \\\n",
    "            grid.cv_results_['split4_test_score'][grid.best_index_]\n",
    "\n",
    "print(\"\\n===== Cross-Validation Scores (5 folds) =====\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"Fold {i} Accuracy: {score:.4f}\")\n",
    "\n",
    "print(\"\\n===== Mean Cross-Validation Accuracy =====\")\n",
    "print(f\"Mean Accuracy: {grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test data\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n===== Test Accuracy =====\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\n===== Confusion Matrix =====\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n===== Classification Report =====\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76ee41-4c0a-4a08-a6a3-1cd2805f6a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    },
    {
     "datasetId": 11657,
     "sourceId": 16098,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 666964,
     "sourceId": 1175021,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.310723,
   "end_time": "2025-12-10T18:58:24.540619",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-10T18:57:43.229896",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
